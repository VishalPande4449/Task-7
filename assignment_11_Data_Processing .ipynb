{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment 11 Data Processing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DATA PREPROCESSING"
      ],
      "metadata": {
        "id": "4I2X96b75VND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Importing the libraries**"
      ],
      "metadata": {
        "id": "LrQA66FF5acX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ddkb-3u5T8L"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Importing dataset"
      ],
      "metadata": {
        "id": "lsyVXSyv5mFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "YppBLFds5oYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "kCoJ4iYm55zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "id": "8AHhJjJr57D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "mMURgitp58al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Handling the missing data**"
      ],
      "metadata": {
        "id": "Oy-fHcpp5-9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "TxAflWVd6BPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['Age', 'Salary']] = df[['Age', 'Salary']].fillna(df[['Age', 'Salary']].mean())\n",
        "#or df = df.fillna(df.median()) it will act for all columns\n"
      ],
      "metadata": {
        "id": "0H8Y98Pp6EaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "QXEsE9Pe6FgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Encoding categorical data\n",
        "\n",
        "To extract distinct values for all categorical columns in dataframe **"
      ],
      "metadata": {
        "id": "9ZerMxf86Iw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code given below was refered from stackoverflow. link text\n",
        "\n"
      ],
      "metadata": {
        "id": "isBFWo1P6R1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_unique = df.nunique().to_frame().reset_index()\n",
        "df_unique.columns = ['Variable','DistinctCount']\n",
        "df_unique"
      ],
      "metadata": {
        "id": "CWkZfjF36TSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the country and purchased columns we have 3 and 2 categorical values presented respectively.\n",
        "\n",
        "First we are encoding the target variable 'Purchased' to 0 and 1."
      ],
      "metadata": {
        "id": "X-vJooCh6U_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df['Purchased'] = df['Purchased'].map({'Yes':True ,'No':False})\n",
        "# #OR\n",
        "# df['Purchased'] = df['Purchased'].map(dict(Yes=1, No=0))\n",
        "# #OR\n",
        "df['Purchased'] = df['Purchased'].eq('Yes').mul(1)"
      ],
      "metadata": {
        "id": "NwHZ0BKk6Wwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "YGYGZ9kI6X5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we need to apply one hot encoding to country(feature variable). Befor that we need to create dummy variables.\n"
      ],
      "metadata": {
        "id": "TIOMJSsY6aYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Creating a dummy variable**"
      ],
      "metadata": {
        "id": "fT2Zh4Zg6c3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = []\n",
        "for i in df.keys():\n",
        "  b.append(i)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "BOzkPxLI6Zbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, columns = ['Country'])"
      ],
      "metadata": {
        "id": "edS6zjXV6hcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = []\n",
        "for i in df.keys():\n",
        "  b.append(i)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "pI_JWYLf69k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "gyd3d__H6-9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Splitting the datasets into training sets and Test sets**"
      ],
      "metadata": {
        "id": "fpr4eZPd7A7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "id": "1xsXqLsd7Djg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.remove('Purchased')"
      ],
      "metadata": {
        "id": "PCIn_CWI7EyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "id": "ymc9ydlu7GJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[b].values#array of features\n",
        "y = df['Purchased'].values"
      ],
      "metadata": {
        "id": "7Ij9_RFk7Hlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
      ],
      "metadata": {
        "id": "EOyaPzcv7KGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Feature Scaling**"
      ],
      "metadata": {
        "id": "8_m14SiX7Ln3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler ## standrard scalig \n",
        "scaler = StandardScaler() #initialise to a variable\n",
        "scaler.fit(X_train,y_train) # we are finding the values of mean and sd from the td\n",
        "X_train_scaled = scaler.transform(X_train) # fit (mean, sd) and then transform the training data\n",
        "X_test_scaled = scaler.transform(X_test) # transform the test data\n"
      ],
      "metadata": {
        "id": "7d-uaNgy7N9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_scaled)"
      ],
      "metadata": {
        "id": "QzOe6YyC7Pq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test_scaled)"
      ],
      "metadata": {
        "id": "lZeqxzgZ7Tbw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}