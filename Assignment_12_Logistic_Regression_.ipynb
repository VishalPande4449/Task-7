{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 12 Logistic Regression .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LOGISTIC REGRESSION MODEL"
      ],
      "metadata": {
        "id": "kgJlnIFjlR39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset contains information of users in a social network. Those informations are the user id the gender the age and the estimated salary. A car company has just launched their brand new luxury SUV. And we're trying to see which of these users of the social network are going to buy this brand new SUV And the last column here tells If yes or no the user bought this SUV we are going to build a model that is going to predict if a user is going to buy or not the SUV based on two variables which are going to be the age and the estimated salary. So our matrix of feature is only going to be these two columns. We want to find some correlations between the age and the estimated salary of a user and his decision to purchase yes or no the SUV."
      ],
      "metadata": {
        "id": "g_Rf4jNDlZR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 | Data Pre-Processing\n",
        "\n",
        "Importing the Libraries**"
      ],
      "metadata": {
        "id": "X2du2oz5leWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "WouLiPeilYoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the dataset**"
      ],
      "metadata": {
        "id": "wK3Ii2nbln3N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-zoF1vFlQxK"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/Social_Network_Ads.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "hASmQECDmkvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "id": "Dn704OcOmrqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "HpRGc79umufc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "6mo56oMWmy4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unique values in each column\n",
        "df_unique = df.nunique().to_frame().reset_index()\n",
        "df_unique.columns = ['Variable','DistinctCount']\n",
        "df_unique"
      ],
      "metadata": {
        "id": "EpgCTWIlm0qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping the User ID column."
      ],
      "metadata": {
        "id": "BWqs6hMfm4ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(['User ID'], axis=1)"
      ],
      "metadata": {
        "id": "UJ8hgmE3m20Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "juRliKAAm9mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert gender colum to int format.\n",
        "\n",
        "Male is 0\n",
        "\n",
        "Female is 1"
      ],
      "metadata": {
        "id": "AvdS2gaPnFOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Gender'] = df['Gender'].map({'Male':0 ,'Female':1})\n",
        "df.head()"
      ],
      "metadata": {
        "id": "CwG2nj0HnEo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (16, 12))\n",
        "sns.heatmap(df.corr(), annot = True, fmt = '.2%')"
      ],
      "metadata": {
        "id": "sCIS3go4nJ37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  EDA"
      ],
      "metadata": {
        "id": "A0o4wGUknNMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(x=\"Purchased\", y=\"EstimatedSalary\", hue=\"Gender\", kind=\"swarm\", data=df)\n"
      ],
      "metadata": {
        "id": "Kz4iiUD8nRJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(x=\"Purchased\", y=\"Age\", hue=\"Gender\", kind=\"swarm\", data=df)\n"
      ],
      "metadata": {
        "id": "c94ABPvZnU57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the diagram we can tell that Purchased is highly correlated with Age. The Estimatedsalary has also a good correlation.\n",
        "\n",
        "Creatting dummy variables for encoding"
      ],
      "metadata": {
        "id": "mepM7sKhnamf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " = []\n",
        "for i in df.keys():\n",
        "  b.append(i)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "VIl9G_RUnaBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, columns = ['Gender'])"
      ],
      "metadata": {
        "id": "JMI8yIzHnYPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = []\n",
        "for i in df.keys():\n",
        "  b.append(i)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "Ptb6cMvxnhKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "c_3GRwTunlWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the dataset into the Training set and Test set"
      ],
      "metadata": {
        "id": "nfOoZW06n5He"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b.remove('Purchased')"
      ],
      "metadata": {
        "id": "c5kZa3KTn3F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "id": "l1sfLikboCsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[b].values#array of features\n",
        "y = df['Purchased'].values"
      ],
      "metadata": {
        "id": "-3LryN9UoE7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
      ],
      "metadata": {
        "id": "6JrBQ_tdoJoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Scaling**"
      ],
      "metadata": {
        "id": "A2wuFIEgoLZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler ## standrard scalig \n",
        "scaler = StandardScaler() #initialise to a variable\n",
        "scaler.fit(X_train,y_train) # we are finding the values of mean and sd from the td\n",
        "X_train_scaled = scaler.transform(X_train) # fit (mean, sd) and then transform the training data\n",
        "X_test_scaled = scaler.transform(X_test) # transform the test data\n"
      ],
      "metadata": {
        "id": "ZHdTuOe3oOny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 | Logistic Regression Model**"
      ],
      "metadata": {
        "id": "SSzuKryToSrI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The library for this job which is going to be the linear model library and it is called linear because the logistic regression is a linear classifier which means that here since we're in two dimensions, our two categories of users are going to be separated by a straight line. Then import the logistic regression class. Next we will create a new object from this class which is going to be our classifier that we are going to fit on our training set."
      ],
      "metadata": {
        "id": "urgF5AYioV31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting Logistic Regression to the Training set**"
      ],
      "metadata": {
        "id": "N7khhds1ob8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression #main code that build the LR model \n",
        "logistic_regression= LogisticRegression() #initialise the required package\n",
        "logistic_regression.fit(X_train_scaled,y_train) #magic happens - best values of betas - training/learning happens here\n",
        "y_pred=logistic_regression.predict(X_test_scaled)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "pgGvuThUoZrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression.coef_"
      ],
      "metadata": {
        "id": "ATXoEeRfoQjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression.intercept_"
      ],
      "metadata": {
        "id": "bAyOp0hKopJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3 | Predection**"
      ],
      "metadata": {
        "id": "cnWLfNDSos1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "df"
      ],
      "metadata": {
        "id": "BmP83RPvovrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4 | Evaluating The Predection"
      ],
      "metadata": {
        "id": "lxnGCS2jo0qw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We predicted the test results and now we will evaluate if our logistic regression model learned and understood correctly. So this confusion matrix is going to contain the correct predictions that our model made on the set as well as the incorrect predictions."
      ],
      "metadata": {
        "id": "wx53GJe5o4Lh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making the Confusion Matrix"
      ],
      "metadata": {
        "id": "bd070Jvho8oL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k9ZVhI_Oo4HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test,y_pred)"
      ],
      "metadata": {
        "id": "euzsz6zno3J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization**"
      ],
      "metadata": {
        "id": "k5AxEOiipBAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
        "sns.heatmap(confusion_matrix, annot=True)"
      ],
      "metadata": {
        "id": "fW1jZsooozsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p871nesMoyMN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}