{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 13 KNN model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# K- NEAREST NEIGHBORS MODEL"
      ],
      "metadata": {
        "id": "KIw4u2A-pnWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Step 1 | Data Pre-Processing\n",
        "\n",
        "Importing the Libraries**"
      ],
      "metadata": {
        "id": "PuX2OTbRptcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "#from sklearn import datasets, neighbors\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from sklearn.model_selection import cross_val_score # import all the functions reqd for cross validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "Wqk0BAbupsoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the dataset**"
      ],
      "metadata": {
        "id": "81htbyOQp6Z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('content/Social_Network_Ads.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "tTl13rihp21Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aso8i9m-pW3k"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "id": "EZzImMNAqXM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "eCQ3I67lqZFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "N1s7d4Jzqb1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unique values in each column\n",
        "df_unique = df.nunique().to_frame().reset_index()\n",
        "df_unique.columns = ['Variable','DistinctCount']\n",
        "df_unique"
      ],
      "metadata": {
        "id": "AgZ0OVLhqeIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping the User ID column."
      ],
      "metadata": {
        "id": "QRbf3m2Zql2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "9y9fxLqUqq2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert gender colum to int format.\n",
        "\n",
        "Male is 0\n",
        "\n",
        "Female is 1"
      ],
      "metadata": {
        "id": "L-iE_KGNq0S1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Gender'] = df['Gender'].map({'Male':0 ,'Female':1})\n",
        "df.head()"
      ],
      "metadata": {
        "id": "qcUNB7LZq2sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (16, 12))\n",
        "sns.heatmap(df.corr(), annot = True, fmt = '.2%')"
      ],
      "metadata": {
        "id": "owh4aIoWq5UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA"
      ],
      "metadata": {
        "id": "miYHUzY6q73x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(x=\"Purchased\", y=\"EstimatedSalary\", hue=\"Gender\", kind=\"swarm\", data=df)\n"
      ],
      "metadata": {
        "id": "TqTpAQyHq-zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(x=\"Purchased\", y=\"Age\", hue=\"Gender\", kind=\"swarm\", data=df)\n"
      ],
      "metadata": {
        "id": "jFsraHmJrBen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the diagram we can tell that Purchased is highly correlated with Age. The Estimatedsalary has also a good correlation.\n",
        "\n",
        "Creatting dummy variables for encoding"
      ],
      "metadata": {
        "id": "1lHO0LAXrImB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = []\n",
        "for i in df.keys():\n",
        "  b.append(i)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "gtPwbwFkrGpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, columns = ['Gender'])"
      ],
      "metadata": {
        "id": "qvoTIoyzrMxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = []\n",
        "for i in df.keys():\n",
        "  b.append(i)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "jKpIfZCZrOXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "c-_uiq6srQC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Fitting K-NN to the Training set\n",
        "\n",
        "Splitting the dataset into the Training set and Test set**"
      ],
      "metadata": {
        "id": "JUtVWQfFrTzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b.remove('Purchased')"
      ],
      "metadata": {
        "id": "2iQ8ViT_rTCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "id": "PqnR1_HLrd0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[b].values#array of features\n",
        "y = df['Purchased'].values"
      ],
      "metadata": {
        "id": "gbZQuvQ4rf20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
      ],
      "metadata": {
        "id": "oJC-sQMori7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Scaling**"
      ],
      "metadata": {
        "id": "XbCK3GQAruT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler ## standrard scalig \n",
        "scaler = StandardScaler() #initialise to a variable\n",
        "scaler.fit(X_train,y_train) # we are finding the values of mean and sd from the td\n",
        "X_train_scaled = scaler.transform(X_train) # fit (mean, sd) and then transform the training data\n",
        "X_test_scaled = scaler.transform(X_test) # transform the test data\n"
      ],
      "metadata": {
        "id": "SCedpGBLrzK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting the kNN model**"
      ],
      "metadata": {
        "id": "2GZsLWE7r1zK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [1,2,3,4,5,6,7,8,9,10,20,50]:\n",
        "  knn = KNeighborsClassifier(i) #initialising the model\n",
        "  knn.fit(X_train_scaled,y_train) # training the model\n",
        "  print(\"K value  : \" , i, \" score : \", np.mean(cross_val_score(knn, X_train_scaled, y_train, cv=10))) #predicting using the model\n"
      ],
      "metadata": {
        "id": "uGbYm09Br04S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For k=5 we have 89% of accuracy."
      ],
      "metadata": {
        "id": "br4UYCAur7e8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(5) #it will initialise the model with @neighbours as k \n",
        "knn.fit(X_train_scaled, y_train) # train the model\n",
        "print(\"Train Accuracy : \", knn.score(X_train_scaled,y_train)) # test the model and it computes the accuracy (train data accuracy)\n",
        "print(\"Val Accuracy : \", np.mean(cross_val_score(knn, X_train_scaled, y_train, cv=10)))\n"
      ],
      "metadata": {
        "id": "1pp4RJ8lr9gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicting the Test set results**"
      ],
      "metadata": {
        "id": "-aUxP5Zsr_v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = knn.predict(X_test_scaled)\n",
        "results"
      ],
      "metadata": {
        "id": "ytpTsYbEr_Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'Actual': y_test, 'Predicted': results})\n",
        "df"
      ],
      "metadata": {
        "id": "vj-wFAntsEDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Making the Confusion Matrix**"
      ],
      "metadata": {
        "id": "olB4B0PisKT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test,results)"
      ],
      "metadata": {
        "id": "fl9AWsb5sGdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization"
      ],
      "metadata": {
        "id": "31YT-hE1sV15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix = pd.crosstab(y_test, results, rownames=['Actual'], colnames=['Predicted'])\n",
        "sns.heatmap(confusion_matrix, annot=True)"
      ],
      "metadata": {
        "id": "fKxfQm5YsaXb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}